{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Script for generating the training and testing data sets for desirable galaxy types\n",
        "\n",
        "The script follows after **02. Reading and Processing SDSS data.ipynb (in short; 02)** and uses the data files generated in that notebook. The current script can be run locally on the computer after obtaining the data sets remotely from **02** *lesta*. The aim of this script is to generate the training and testing data sets that is used to produce deep learning models for the three category classification of galaxy types.\n",
        "\n",
        "1. Defining the input parameters\n",
        "2. Preliminary preperation of the training and testing sets\n",
        "3. Generation of the training and testing data sets\n",
        "\n",
        "**Data**: 11th Nov, 2019 <br>\n",
        "**Author**: Soumya Shreeram <br>\n",
        "**Guidance from**: Anand Raichoor <br>\n",
        "**Script adapted from:** S. Ben Nejma\n"
      ],
      "metadata": {
        "inputHidden": false,
        "outputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'font.size': 20})\n",
        "import numpy as np\n",
        "from numpy.lib.format import open_memmap\n",
        "import os, sys\n",
        "import subprocess\n",
        "import random"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Defining the input parameters"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# setting the right path for the directory with the data\n",
        "current_dir = os.getcwd()\n",
        "data_dir = os.path.join(current_dir, \"Data_files\")\n",
        "\n",
        "# ratio with which the data is separated for training and testing\n",
        "ratio = 0.7"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "inputHidden": false,
        "outputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def writeOutputToFile(input_name, shape_arr, in_dtype):\n",
        "    \"\"\"\n",
        "    Write to a .npy file as a memory-mapped array\n",
        "    @param input_name :: array name\n",
        "    @param shape_arr :: shape of the array to be memory-mapped\n",
        "    \n",
        "    @return output_arr :: the memory-mapped array\n",
        "    \"\"\"\n",
        "    filename =  'Data_files/'+input_name+'.npy'\n",
        "    w1 = open_memmap(filename, dtype=in_dtype, mode='w+', shape=shape_arr)\n",
        "    return w1"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "inputHidden": false,
        "outputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Preliminary preperation of the training and testing sets\n",
        "\n",
        "Following the functions in the succeeding code cell, which are responsible for generation of training and testing data sets, a brief explanation of the sample processing is given."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def createCategoryList(Y, ratio):\n",
        "    \"\"\"\n",
        "    Function creates a list of indexes for every category (galaxy type) in the sample\n",
        "    \"\"\"\n",
        "    # lists of the different labels, and aranging indicies\n",
        "    categories = np.unique(Y).astype(int)\n",
        "    indexes = np.arange(len(Y))\n",
        "\n",
        "    # minimum no. of samples to choose for each catergory/type of galaxy\n",
        "    min_samples = np.array([int(ratio*len(Y[Y == i])) for i in categories])\n",
        "\n",
        "    #  list of indicies for every target type, and shuffling them at random\n",
        "    category_indexes = [indexes[Y == i] for i in categories]\n",
        "    for i in categories:\n",
        "        random.shuffle(category_indexes[i])\n",
        "    return category_indexes, categories, min_samples\n",
        "\n",
        "def testTrainIndexes(category_indexes, categories, min_samples, train, test):\n",
        "    \"\"\"\n",
        "    Function produces the indicies used for generating training and testing samples\n",
        "    \"\"\"\n",
        "    if train:\n",
        "        indexes_interm = [category_indexes[i][:min_samples[i]]\n",
        "                                for i in categories]\n",
        "    elif test:\n",
        "        indexes_interm = [category_indexes[i][min_samples[i]:]\n",
        "                                for i in categories]\n",
        "    indexes = np.array([idx for categories in indexes_interm\n",
        "                              for idx in categories])\n",
        "    random.shuffle(indexes)\n",
        "    return indexes\n",
        "\n",
        "def generateTrainTestFiles(len_train, X):\n",
        "    \"\"\"\n",
        "    Function to generate empty memory-mapped files for training and testing data sets\n",
        "    \"\"\"\n",
        "    X_train = writeOutputToFile('X_train', (len_train, X.shape[1]), 'float32')\n",
        "    Y_train = writeOutputToFile('Y_train', (len_train,), 'float32')\n",
        "    \n",
        "    X_test =  writeOutputToFile('X_test', (X.shape[0]-len_train, X.shape[1]), 'float32')\n",
        "    Y_test = writeOutputToFile('Y_test', (X.shape[0]-len_train,), 'float32')\n",
        "    return X_train, Y_train, X_test, Y_test"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "inputHidden": false,
        "outputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The X, Y data sets that were generated by running the notebook 02 on *lesta* cluster are loaded.\n",
        "* X $\\equiv Flux\\ {\\rm values}\\ \\forall\\ {\\rm waveslengths}$\n",
        "* Y $\\equiv Target-type$ i.e. Quasars, Galaxies, Other $\\forall\\ {\\rm fibres}$ "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the (X, Y) == (flux, target-types)data sets\n",
        "X = np.load('Data_files/X_corrupted.npy', mmap_mode='r')\n",
        "Y = np.load('Data_files/Y_corrupted.npy', mmap_mode='r')"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "inputHidden": false,
        "outputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code block creates a list of all categories of target-types, and selects the percentage of every type as defined by the quantity $ratio$ (see start of the code). The indicies of these cataegories are processed rather than the catergory list itself; this is to reduce the computational cost of processing high-dimensional samples. Finally, the list of indicies for training and testing (${\\rm indexes\\_train,\\ indexes\\_test}$) are generated. \n",
        "\n",
        "Empty memory-mapped arrays are generated to successively save the X, Y values for training and testing purposes."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# creates lists of indexes\n",
        "category_indexes, categories, min_samples = createCategoryList(Y, ratio)\n",
        "\n",
        "# Generates the indicies for training and testing\n",
        "indexes_train = testTrainIndexes(category_indexes, categories, min_samples, train=True, test=False)\n",
        "indexes_test = testTrainIndexes(category_indexes, categories, min_samples, train=False, test=True)\n",
        "\n",
        "# Creates empty memory-mapped array for the (X, Y) training and testing samples\n",
        "len_train = np.sum(min_samples)\n",
        "X_train, Y_train, X_test, Y_test = generateTrainTestFiles(len_train, X)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "inputHidden": false,
        "outputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Generation of the training and testing data sets\n",
        "The following two lines saves the values of the fluxes (X) and target types (Y) for training and testing samples. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[:], Y_train[:] = X[indexes_train], Y[indexes_train]\n",
        "X_test[:], Y_test[:] = X[indexes_test], Y[indexes_test]"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "inputHidden": false,
        "outputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of [X, Y] training data sets: \", [np.shape(X_train), np.shape(Y_train)])\n",
        "print(\"Shape of [X, Y] testing data sets: \", [np.shape(X_test), np.shape(Y_test)])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of [X, Y] training data sets:  [(553301, 4317), (553301,)]\n",
            "Shape of [X, Y] testing data sets:  [(237130, 4317), (237130,)]\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "inputHidden": false,
        "outputHidden": false
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.15.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}