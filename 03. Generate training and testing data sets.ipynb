{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Script for generating the training and testing data sets for desirable galaxy types\n",
        "\n",
        "The script follows after **02. Reading and Processing SDSS data.ipynb (in short; 02)** and uses the data files generated in that notebook. The current script can be run locally on the computer after obtaining the data sets remotely from **02** *lesta*.\n",
        "\n",
        "**Data**: 11th Nov, 2019 <br>\n",
        "**Author**: Soumya Shreeram <br>\n",
        "**Guidance from**: Anand Raichoor <br>\n",
        "**Script adapted from:** S. Ben Nejma\n"
      ],
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import astropy.io.fits as fits\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'font.size': 20})\n",
        "import numpy as np\n",
        "from numpy.lib.format import open_memmap\n",
        "import os, sys\n",
        "import subprocess\n",
        "from astropy.convolution import convolve, Box1DKernel\n",
        "import random"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Defining the input parameters"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# setting the right path for the directory with the data\n",
        "current_dir = os.getcwd()\n",
        "data_dir = os.path.join(current_dir, \"Data_files\")\n",
        "\n",
        "# ratio with which the data is separated for training and testing\n",
        "ratio = 0.7"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def writeOutputToFile(input_name, shape_arr, in_dtype):\n",
        "    \"\"\"\n",
        "    Write to a .npy file as a memory-mapped array\n",
        "    @param input_name :: array name\n",
        "    @param shape_arr :: shape of the array to be memory-mapped\n",
        "    \n",
        "    @return output_arr :: the memory-mapped array\n",
        "    \"\"\"\n",
        "    filename =  'Data_files/'+input_name+'.npy'\n",
        "    w1 = open_memmap(filename, dtype=in_dtype, mode='w+', shape=shape_arr)\n",
        "    return w1"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Preparation of training and testing data sets\n",
        "\n",
        "Following the functions in the succeeding code cell, which are responsible for generation of training and testing data sets, a brief explanation of the sample processing is given."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def createCategoryList(Y, ratio):\n",
        "    \"\"\"\n",
        "    Function creates a list of indexes for every category (galaxy type) in the sample\n",
        "    \"\"\"\n",
        "    # lists of the different labels, and aranging indicies\n",
        "    categories = np.unique(Y).astype(int)\n",
        "    indexes = np.arange(len(Y))\n",
        "\n",
        "    # minimum no. of samples to choose for each catergory/type of galaxy\n",
        "    min_samples = np.array([int(ratio*len(Y[Y == i])) for i in categories])\n",
        "\n",
        "    #  list of indicies for every target type, and shuffling them at random\n",
        "    category_indexes = [indexes[Y == i] for i in categories]\n",
        "    for i in categories:\n",
        "        random.shuffle(category_indexes[i])\n",
        "    return category_indexes, categories, min_samples\n",
        "\n",
        "def testTrainIndexes(category_indexes, categories, min_samples, train, test):\n",
        "    \"\"\"\n",
        "    Function produces the indicies used for generating training and testing samples\n",
        "    \"\"\"\n",
        "    if train:\n",
        "        indexes_interm = [category_indexes[i][:min_samples[i]]\n",
        "                                for i in categories]\n",
        "    elif test:\n",
        "        indexes_interm = [category_indexes[i][min_samples[i]:]\n",
        "                                for i in categories]\n",
        "    indexes = np.array([idx for categories in indexes_interm\n",
        "                              for idx in categories])\n",
        "    random.shuffle(indexes)\n",
        "    return indexes\n",
        "\n",
        "def generateTrainTestFiles(len_train, X):\n",
        "    \"\"\"\n",
        "    Function to generate empty memory-mapped files for training and testing data sets\n",
        "    \"\"\"\n",
        "    X_train = writeOutputToFile('X_train', (len_train, X.shape[1]), 'float32')\n",
        "    Y_train = writeOutputToFile('Y_train', (len_train,), 'float32')\n",
        "    \n",
        "    X_test =  writeOutputToFile('X_test', (X.shape[0]-len_train, X.shape[1]), 'float32')\n",
        "    Y_test = writeOutputToFile('Y_test', (X.shape[0]-len_train,), 'float32')\n",
        "    return X_train, Y_train, X_test, Y_test"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The X, Y data sets that were generated by running the notebook 02 on *lesta* cluster are loaded.\n",
        "* X $\\equiv Flux\\ {\\rm values}\\ \\forall\\ {\\rm waveslengths}$\n",
        "* Y $\\equiv Target-type$ i.e. Quasars, Galaxies, Other $\\forall\\ {\\rm fibres}$ "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the (X, Y) == (flux, target-types)data sets\n",
        "X = np.load('Data_files/X_corrupted.npy', mmap_mode='r')\n",
        "Y = np.load('Data_files/Y_corrupted.npy', mmap_mode='r')"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code block creates a list of all categories of target-types, and selects the percentage of every type as defined by the quantity $ratio$ (see start of the code). The indicies of these cataegories are processed rather than the catergory list itself; this is to reduce the computational cost of processing high-dimensional samples. Finally, the list of indicies for training and testing (${\\rm indexes\\_train,\\ indexes\\_test}$) are generated. \n",
        "\n",
        "Empty memory-mapped arrays are generated to successively save the X, Y values for training and testing purposes."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# creates lists of indexes\n",
        "category_indexes, categories, min_samples = createCategoryList(Y, ratio)\n",
        "\n",
        "# Generates the indicies for training and testing\n",
        "indexes_train = testTrainIndexes(category_indexes, categories, min_samples, train=True, test=False)\n",
        "indexes_test = testTrainIndexes(category_indexes, categories, min_samples, train=False, test=True)\n",
        "\n",
        "# Creates empty memory-mapped array for the (X, Y) training and testing samples\n",
        "len_train = np.sum(min_samples)\n",
        "X_train, Y_train, X_test, Y_test = generateTrainTestFiles(len_train, X)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following two lines saves the values of the fluxes (X) and target types (Y) for training and testing samples. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[:], Y_train[:] = X[indexes_train], Y[indexes_train]\n",
        "X_test[:], Y_test[:] = X[indexes_test], Y[indexes_test]"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of [X, Y] training data sets: \", [np.shape(X_train), np.shape(Y_train)])\n",
        "print(\"Shape of [X, Y] testing data sets: \", [np.shape(X_test), np.shape(Y_test)])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of [X, Y] training data sets:  [(7033, 4317), (7033,)]\n",
            "Shape of [X, Y] testing data sets:  [(3015, 4317), (3015,)]\n"
          ]
        }
      ],
      "execution_count": 18,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "nteract": {
      "version": "0.15.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}